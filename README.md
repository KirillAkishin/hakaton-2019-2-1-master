Пишем своего рода поисковую систему.

web <-> workerX <- workerX.txt <- writter <- emiter <- amazon-meta.txt

https://docs.google.com/presentation/d/1Xmj8RS2XPlzyugaX-x2GWOi-twjxHbi9vfE9KsjMxKU/edit?usp=sharing

-----

WEB
веб интерфейс который возволяет ввести запрос вида
select (stream|stat|online) $fields from $table [ where group = XXX ]
где $fields = (Id,Time,ASIN,title,group,salesrank) или *
т.е. допускается одно из полей или все
$table = amazon_reviews (только)
group = (Baby|Book|CE|DVD|Music|Software|Sports|Toy|Video)

запрос положится во внутреннее хранилище (про sql мы ничего не знаем, пишем csv|json|csv на диск) с присвоением ему ID=md5(unix_time) и отправится на все воркеры (WORKER)

соединение с воркерами двустороннее, по tcp, т.е. WEB посылает данные в WORKER и наоборот, WORKER посылает в WEB

(stream|stat|online) - режимы работы

* stream - данные по мере поиска попадают в WEB, где их можно посмотреть
* stat - статистика по данным, в виде time_minute - count
* online - реализовать в последнюю очередь. можно использовать пакет https://github.com/fsnotify/fsnotify. данные стримятся в WEB по мере поступления в data в режиме online

скриншот интерфейса https://s.mail.ru/6M6E/FSxtJmcfr - это 3 разных страницы

C воркером обрщаются по самодельному бинарному асинхронному протоколу поверх TCP (т.е. не HTTP)

Формат протокола
<msg_id:uint32><seq:uint32><data_len:uint32><data_json:[]byte><data_crc32:uint32>

msg_id - код комманды
seq - автоинкрементный счетчик
data_len - длина данных
data_json - данные, запакованные в json
data_crc32 - хеш-сумма от пересланных данных

соединение устанавливает воркер - он знает адрес веб-а

для общения по бинарному протоколу смотрите пример 3/1_net

-----

WORKER
основной сервис поиска

работает в 3-х режимах:
1. stream - ищет данные по workerX.txt со скоростью не более 1000 записей/сек (1000 конфигурится), что нашлось - отправляет в WEB
2. stat - осуществляет поиск по всему файлу со скоростью не более 1000 записей/сек (1000 конфигурится), считает стаистику в виде time_minute - count и отправляет её в WEB
3. online - мониторит файл, обрабатывая каждую запись, если попадает под фильтры - отсылает в WEB. реализовать в последнюю очередь

В случае если приходят несколько заданий - он дайёт каждой задаче поработаь по 10 сек, потом переключается

статус воркера надо сохранять на диск - можно тупо json - т.е. если вокрер падает - он поднимается с последнего сохранённого состояния

моежт быть запущен в нескольких экземплярах

-----

DATA ( workerX.txt )
просто данные на диске
куда постоянно пишет writer

-----

WRITE
Сервис который принимает по сети (http) данные и пишет на диск (workerX.txt)
поднят в нескольких экземплярах, количество равно количеству воркеров. Т.е. сколько воркеров - столько врайтеров - столько файлов с данными.
К данным добавляет поле Time (текущее значение времени)
Данные пишет в папку соответствующего WORKERа

-----

EMITER
сервис который читает данные из amazon-meta.txt.gz, берёт crc32(id) % WORKERS_COUNT и шлёт в соответствующий ему WRITER
рейт - не более 1 записи в секунду ( под конфигом)
данные шлёт все что там есть - парсит всё, а не только то что мы выше можем указать

данные будут лежат на сервере 
/var/tmp/amazon-meta.txt.gz

скачать в вебе
https://cloud.mail.ru/public/Drsk/FpkBV7TF4

оригинал ( оттуда медленно качается )
https://snap.stanford.edu/data/amazon-meta.html


-----


Код пишем у себя на ноутах, для отладки у вас есть сервак, где можно всё запустить вместе.
Код в гите, репу не клоним! работаем прямо в ней, пишем в отдельных ветках, когда надо - мерджимся.


Задача параллелится на следующие подзадачи:

0. протокол общения - какие структуры, чего куда, в каком формате храним данные
1. парсинг запроса
2. страницы вывода списка задач + результатов
3. реализация протокола общения с воркером - сетевой слой
4. сохранение результатов и списока задач
5. воркер - очередь и переключалка задач, статус задач, статистика по задачам
6. воркер - stream-поиск
7. воркер - stat-поиск
8. writer - приём данных, время, сохранение на диск
9. emiter - парсинг файла, выборка нужного, отправка во writer
-- дополнительный функционал (когда остальное заработает)
10. worker - онлайн-поиск
11. web - онлайн-поиск

-----

порядок работы:

0. обсудить задачу в целом
1. выбрать координаторов, которые будут отвечать за взаимодействие между командами и общий успех
2. разбиться на команды
3. обсудить задачу команды
4. обсудить протоколы общения с взаимодействующими компонентами ( т.е. worker обсуждает протокол с web, а так же формат данных с writer; writer - формат данных на диске с worker, формат приёма данных с emiter )
5. начинать писать код

внимание! 

* если не будет координатора - будет хаотичная разработка и в итоге ничего не заработает
* если вы не договоритесь о форматах и прочем, а сразу же броситесь писать код - в итоге выяснится, что компоненты между собой не совместимы и ничего не работает
* если вы начнете интегрироваться в конце - скорее всего ничего не заработает. интеграцию надо или начинать с самого начала, или, хотя бы, в середине дня

проверено :)

писать код лучше в режиме парного-тройного программирования, периодически меняясь у клавиатуры

-----

так же вам надо будет заполнить отчет по результатам хакатона и ответить на следущие вопросы

1. над каким компонентом вы работали, что именно вы писали
2. кто работал вместе с вами в команде
3. с какими проблемами/трудностями вы встрелились (любого характера)
4. какие знания вам пригодились, какие знания вы применяли
5. каких знаний вам не хватило и пришлось быстро гуглить, читатть доку, разбираться
6. что получилось, почему?
7. что не получилось, почему?
8. что лично вы могли бы сделать лучше в следующий раз
9. что вы, как команда, могли бы сделать лучше в следующий раз

отчет закоммитить в свой репозиторий (не в хакатоновский!) в формате md ( это обычный текстовый файл ) с именем `hakaton1.md`

Без отчета баллы не выставляется

-----

Сервер:

IP: выдадим чуть позде

Логин: ваш логин на гитлабе

Пароль: dsuyuyduaudijijhugvyuykjhaljnxaxaxa

